{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Given a bank customer, build a neural network-based classifier that can determine whether they will leave or not in the \n",
    "next 6 months. Dataset Description: The case study is from an open-source dataset from Kaggle. The dataset contains 10,000\n",
    "sample points with 14 distinct features such as Customer Id, Credit Score, Geography, Gender, Age, Tenure, Balance, etc.\n",
    "\n",
    "Perform following steps: 1. Read the dataset. 2. Distinguish the feature and target set and divide the data set into \n",
    "training and test sets. 3. Normalize the train and test data. 4. Initialize and build the model. Identify the points of\n",
    "improvement and implement the same. 5. Print the accuracy score and confusion matrix (5 points).\n",
    "\n",
    "Write  theory of neural network based classifier for bank customer churn\n",
    "\n",
    "submit file with file name as : rollno_assignment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.009067</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>0.004202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.027094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.285323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.028362</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>-0.009067</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.118533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.047820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.028362</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>-0.156128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.005988</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.027094</td>\n",
       "      <td>0.285323</td>\n",
       "      <td>-0.014001</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>-0.047820</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>-0.156128</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowNumber  CustomerId  CreditScore       Age    Tenure  \\\n",
       "RowNumber         1.000000    0.004202     0.005840  0.000783 -0.006495   \n",
       "CustomerId        0.004202    1.000000     0.005308  0.009497 -0.014883   \n",
       "CreditScore       0.005840    0.005308     1.000000 -0.003965  0.000842   \n",
       "Age               0.000783    0.009497    -0.003965  1.000000 -0.009997   \n",
       "Tenure           -0.006495   -0.014883     0.000842 -0.009997  1.000000   \n",
       "Balance          -0.009067   -0.012419     0.006268  0.028308 -0.012254   \n",
       "NumOfProducts     0.007246    0.016972     0.012238 -0.030680  0.013444   \n",
       "HasCrCard         0.000599   -0.014025    -0.005458 -0.011721  0.022583   \n",
       "IsActiveMember    0.012044    0.001665     0.025651  0.085472 -0.028362   \n",
       "EstimatedSalary  -0.005988    0.015271    -0.001384 -0.007201  0.007784   \n",
       "Exited           -0.016571   -0.006248    -0.027094  0.285323 -0.014001   \n",
       "\n",
       "                  Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber       -0.009067       0.007246   0.000599        0.012044   \n",
       "CustomerId      -0.012419       0.016972  -0.014025        0.001665   \n",
       "CreditScore      0.006268       0.012238  -0.005458        0.025651   \n",
       "Age              0.028308      -0.030680  -0.011721        0.085472   \n",
       "Tenure          -0.012254       0.013444   0.022583       -0.028362   \n",
       "Balance          1.000000      -0.304180  -0.014858       -0.010084   \n",
       "NumOfProducts   -0.304180       1.000000   0.003183        0.009612   \n",
       "HasCrCard       -0.014858       0.003183   1.000000       -0.011866   \n",
       "IsActiveMember  -0.010084       0.009612  -0.011866        1.000000   \n",
       "EstimatedSalary  0.012797       0.014204  -0.009933       -0.011421   \n",
       "Exited           0.118533      -0.047820  -0.007138       -0.156128   \n",
       "\n",
       "                 EstimatedSalary    Exited  \n",
       "RowNumber              -0.005988 -0.016571  \n",
       "CustomerId              0.015271 -0.006248  \n",
       "CreditScore            -0.001384 -0.027094  \n",
       "Age                    -0.007201  0.285323  \n",
       "Tenure                  0.007784 -0.014001  \n",
       "Balance                 0.012797  0.118533  \n",
       "NumOfProducts           0.014204 -0.047820  \n",
       "HasCrCard              -0.009933 -0.007138  \n",
       "IsActiveMember         -0.011421 -0.156128  \n",
       "EstimatedSalary         1.000000  0.012097  \n",
       "Exited                  0.012097  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smith       32\n",
      "Scott       29\n",
      "Martin      29\n",
      "Walker      28\n",
      "Brown       26\n",
      "            ..\n",
      "Izmailov     1\n",
      "Bold         1\n",
      "Bonham       1\n",
      "Poninski     1\n",
      "Burbidge     1\n",
      "Name: Surname, Length: 2932, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Surname'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns = ['Geography', 'Gender'],drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  int64  \n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  uint8  \n",
      " 10  Geography_Spain    10000 non-null  uint8  \n",
      " 11  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(7), uint8(3)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Exited', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.DataFrame(df_encoded, columns =['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
    "       'Exited','Geography_Germany','Geography_Spain','Gender_Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded['Exited']\n",
    "X = df_encoded.drop(columns=['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_encoded =scaler.fit_transform(X)\n",
    "# df_encoded = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246488</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.066419</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0.912419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391939</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.724464</td>\n",
       "      <td>-0.306379</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0.912419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604988</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.008643</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256835</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>-0.022608</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>1.727904</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>0.912419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463771</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-1.076370</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "      <td>-1.095988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0       -0.326221  0.293517 -1.041760 -1.225848      -0.911583   0.646092   \n",
       "1       -0.440036  0.198164 -1.387538  0.117350      -0.911583  -1.547768   \n",
       "2       -1.536794  0.293517  1.032908  1.333053       2.527057   0.646092   \n",
       "3        0.501521  0.007457 -1.387538 -1.225848       0.807737  -1.547768   \n",
       "4        2.063884  0.388871 -1.041760  0.785728      -0.911583   0.646092   \n",
       "...           ...       ...       ...       ...            ...        ...   \n",
       "9995     1.246488  0.007457 -0.004426 -1.225848       0.807737   0.646092   \n",
       "9996    -1.391939 -0.373958  1.724464 -0.306379      -0.911583   0.646092   \n",
       "9997     0.604988 -0.278604  0.687130 -1.225848      -0.911583  -1.547768   \n",
       "9998     1.256835  0.293517 -0.695982 -0.022608       0.807737   0.646092   \n",
       "9999     1.463771 -1.041433 -0.350204  0.859965      -0.911583   0.646092   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "0           0.970243         0.021886          -0.578736        -0.573809   \n",
       "1           0.970243         0.216534          -0.578736         1.742740   \n",
       "2          -1.030670         0.240687          -0.578736        -0.573809   \n",
       "3          -1.030670        -0.108918          -0.578736        -0.573809   \n",
       "4           0.970243        -0.365276          -0.578736         1.742740   \n",
       "...              ...              ...                ...              ...   \n",
       "9995       -1.030670        -0.066419          -0.578736        -0.573809   \n",
       "9996        0.970243         0.027988          -0.578736        -0.573809   \n",
       "9997        0.970243        -1.008643          -0.578736        -0.573809   \n",
       "9998       -1.030670        -0.125231           1.727904        -0.573809   \n",
       "9999       -1.030670        -1.076370          -0.578736        -0.573809   \n",
       "\n",
       "      Gender_Male  \n",
       "0       -1.095988  \n",
       "1       -1.095988  \n",
       "2       -1.095988  \n",
       "3       -1.095988  \n",
       "4       -1.095988  \n",
       "...           ...  \n",
       "9995     0.912419  \n",
       "9996     0.912419  \n",
       "9997    -1.095988  \n",
       "9998     0.912419  \n",
       "9999    -1.095988  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.DataFrame(X_encoded,columns=X.columns)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_encoded,y,test_size=0.2,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 9)                 108       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 60        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175\n",
      "Trainable params: 175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "#Initialize ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Add input layer and hidden layer\n",
    "classifier.add(Dense(9, activation = 'relu', input_shape = (11, )))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "#Add second layer\n",
    "classifier.add(Dense(6, activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "#Add output layer\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "#Let us take a look at our network\n",
    "classifier.summary()\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225/225 - 1s - loss: 0.5580 - accuracy: 0.7918 - val_loss: 0.5150 - val_accuracy: 0.7825 - 1s/epoch - 5ms/step\n",
      "Epoch 2/200\n",
      "225/225 - 0s - loss: 0.4842 - accuracy: 0.7981 - val_loss: 0.4673 - val_accuracy: 0.7837 - 243ms/epoch - 1ms/step\n",
      "Epoch 3/200\n",
      "225/225 - 0s - loss: 0.4504 - accuracy: 0.8062 - val_loss: 0.4456 - val_accuracy: 0.8150 - 237ms/epoch - 1ms/step\n",
      "Epoch 4/200\n",
      "225/225 - 0s - loss: 0.4377 - accuracy: 0.8140 - val_loss: 0.4369 - val_accuracy: 0.8250 - 226ms/epoch - 1ms/step\n",
      "Epoch 5/200\n",
      "225/225 - 0s - loss: 0.4245 - accuracy: 0.8163 - val_loss: 0.4329 - val_accuracy: 0.8288 - 272ms/epoch - 1ms/step\n",
      "Epoch 6/200\n",
      "225/225 - 0s - loss: 0.4208 - accuracy: 0.8224 - val_loss: 0.4271 - val_accuracy: 0.8375 - 316ms/epoch - 1ms/step\n",
      "Epoch 7/200\n",
      "225/225 - 0s - loss: 0.4212 - accuracy: 0.8204 - val_loss: 0.4245 - val_accuracy: 0.8375 - 277ms/epoch - 1ms/step\n",
      "Epoch 8/200\n",
      "225/225 - 0s - loss: 0.4161 - accuracy: 0.8229 - val_loss: 0.4227 - val_accuracy: 0.8375 - 288ms/epoch - 1ms/step\n",
      "Epoch 9/200\n",
      "225/225 - 0s - loss: 0.4086 - accuracy: 0.8240 - val_loss: 0.4182 - val_accuracy: 0.8388 - 267ms/epoch - 1ms/step\n",
      "Epoch 10/200\n",
      "225/225 - 0s - loss: 0.4090 - accuracy: 0.8269 - val_loss: 0.4141 - val_accuracy: 0.8475 - 254ms/epoch - 1ms/step\n",
      "Epoch 11/200\n",
      "225/225 - 0s - loss: 0.4004 - accuracy: 0.8313 - val_loss: 0.4081 - val_accuracy: 0.8487 - 260ms/epoch - 1ms/step\n",
      "Epoch 12/200\n",
      "225/225 - 0s - loss: 0.3924 - accuracy: 0.8351 - val_loss: 0.4012 - val_accuracy: 0.8562 - 247ms/epoch - 1ms/step\n",
      "Epoch 13/200\n",
      "225/225 - 0s - loss: 0.3870 - accuracy: 0.8406 - val_loss: 0.3918 - val_accuracy: 0.8612 - 234ms/epoch - 1ms/step\n",
      "Epoch 14/200\n",
      "225/225 - 0s - loss: 0.3749 - accuracy: 0.8426 - val_loss: 0.3856 - val_accuracy: 0.8637 - 313ms/epoch - 1ms/step\n",
      "Epoch 15/200\n",
      "225/225 - 1s - loss: 0.3778 - accuracy: 0.8424 - val_loss: 0.3819 - val_accuracy: 0.8550 - 602ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "225/225 - 0s - loss: 0.3706 - accuracy: 0.8454 - val_loss: 0.3804 - val_accuracy: 0.8550 - 318ms/epoch - 1ms/step\n",
      "Epoch 17/200\n",
      "225/225 - 0s - loss: 0.3717 - accuracy: 0.8451 - val_loss: 0.3760 - val_accuracy: 0.8562 - 279ms/epoch - 1ms/step\n",
      "Epoch 18/200\n",
      "225/225 - 0s - loss: 0.3652 - accuracy: 0.8471 - val_loss: 0.3740 - val_accuracy: 0.8562 - 255ms/epoch - 1ms/step\n",
      "Epoch 19/200\n",
      "225/225 - 0s - loss: 0.3662 - accuracy: 0.8467 - val_loss: 0.3756 - val_accuracy: 0.8537 - 259ms/epoch - 1ms/step\n",
      "Epoch 20/200\n",
      "225/225 - 0s - loss: 0.3624 - accuracy: 0.8478 - val_loss: 0.3726 - val_accuracy: 0.8537 - 234ms/epoch - 1ms/step\n",
      "Epoch 21/200\n",
      "225/225 - 0s - loss: 0.3630 - accuracy: 0.8458 - val_loss: 0.3743 - val_accuracy: 0.8550 - 411ms/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "225/225 - 0s - loss: 0.3650 - accuracy: 0.8496 - val_loss: 0.3702 - val_accuracy: 0.8587 - 236ms/epoch - 1ms/step\n",
      "Epoch 23/200\n",
      "225/225 - 0s - loss: 0.3617 - accuracy: 0.8482 - val_loss: 0.3693 - val_accuracy: 0.8575 - 235ms/epoch - 1ms/step\n",
      "Epoch 24/200\n",
      "225/225 - 0s - loss: 0.3604 - accuracy: 0.8506 - val_loss: 0.3700 - val_accuracy: 0.8587 - 432ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "225/225 - 0s - loss: 0.3629 - accuracy: 0.8476 - val_loss: 0.3688 - val_accuracy: 0.8575 - 249ms/epoch - 1ms/step\n",
      "Epoch 26/200\n",
      "225/225 - 0s - loss: 0.3587 - accuracy: 0.8499 - val_loss: 0.3673 - val_accuracy: 0.8550 - 247ms/epoch - 1ms/step\n",
      "Epoch 27/200\n",
      "225/225 - 0s - loss: 0.3639 - accuracy: 0.8447 - val_loss: 0.3673 - val_accuracy: 0.8587 - 270ms/epoch - 1ms/step\n",
      "Epoch 28/200\n",
      "225/225 - 0s - loss: 0.3589 - accuracy: 0.8522 - val_loss: 0.3665 - val_accuracy: 0.8550 - 266ms/epoch - 1ms/step\n",
      "Epoch 29/200\n",
      "225/225 - 0s - loss: 0.3593 - accuracy: 0.8500 - val_loss: 0.3658 - val_accuracy: 0.8587 - 245ms/epoch - 1ms/step\n",
      "Epoch 30/200\n",
      "225/225 - 0s - loss: 0.3605 - accuracy: 0.8503 - val_loss: 0.3678 - val_accuracy: 0.8600 - 250ms/epoch - 1ms/step\n",
      "Epoch 31/200\n",
      "225/225 - 0s - loss: 0.3579 - accuracy: 0.8493 - val_loss: 0.3676 - val_accuracy: 0.8587 - 257ms/epoch - 1ms/step\n",
      "Epoch 32/200\n",
      "225/225 - 0s - loss: 0.3590 - accuracy: 0.8514 - val_loss: 0.3678 - val_accuracy: 0.8625 - 269ms/epoch - 1ms/step\n",
      "Epoch 33/200\n",
      "225/225 - 0s - loss: 0.3540 - accuracy: 0.8506 - val_loss: 0.3666 - val_accuracy: 0.8650 - 245ms/epoch - 1ms/step\n",
      "Epoch 34/200\n",
      "225/225 - 0s - loss: 0.3566 - accuracy: 0.8494 - val_loss: 0.3673 - val_accuracy: 0.8625 - 278ms/epoch - 1ms/step\n",
      "Epoch 35/200\n",
      "225/225 - 0s - loss: 0.3570 - accuracy: 0.8531 - val_loss: 0.3656 - val_accuracy: 0.8600 - 319ms/epoch - 1ms/step\n",
      "Epoch 36/200\n",
      "225/225 - 0s - loss: 0.3495 - accuracy: 0.8564 - val_loss: 0.3643 - val_accuracy: 0.8637 - 278ms/epoch - 1ms/step\n",
      "Epoch 37/200\n",
      "225/225 - 0s - loss: 0.3543 - accuracy: 0.8550 - val_loss: 0.3628 - val_accuracy: 0.8612 - 339ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "225/225 - 0s - loss: 0.3590 - accuracy: 0.8537 - val_loss: 0.3617 - val_accuracy: 0.8625 - 324ms/epoch - 1ms/step\n",
      "Epoch 39/200\n",
      "225/225 - 0s - loss: 0.3557 - accuracy: 0.8529 - val_loss: 0.3622 - val_accuracy: 0.8650 - 340ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "225/225 - 0s - loss: 0.3537 - accuracy: 0.8560 - val_loss: 0.3609 - val_accuracy: 0.8662 - 331ms/epoch - 1ms/step\n",
      "Epoch 41/200\n",
      "225/225 - 0s - loss: 0.3518 - accuracy: 0.8565 - val_loss: 0.3617 - val_accuracy: 0.8650 - 291ms/epoch - 1ms/step\n",
      "Epoch 42/200\n",
      "225/225 - 0s - loss: 0.3588 - accuracy: 0.8542 - val_loss: 0.3600 - val_accuracy: 0.8637 - 313ms/epoch - 1ms/step\n",
      "Epoch 43/200\n",
      "225/225 - 0s - loss: 0.3551 - accuracy: 0.8554 - val_loss: 0.3598 - val_accuracy: 0.8662 - 348ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "225/225 - 0s - loss: 0.3549 - accuracy: 0.8533 - val_loss: 0.3590 - val_accuracy: 0.8637 - 275ms/epoch - 1ms/step\n",
      "Epoch 45/200\n",
      "225/225 - 0s - loss: 0.3517 - accuracy: 0.8550 - val_loss: 0.3586 - val_accuracy: 0.8662 - 359ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "225/225 - 0s - loss: 0.3484 - accuracy: 0.8561 - val_loss: 0.3570 - val_accuracy: 0.8625 - 376ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "225/225 - 0s - loss: 0.3504 - accuracy: 0.8571 - val_loss: 0.3573 - val_accuracy: 0.8612 - 331ms/epoch - 1ms/step\n",
      "Epoch 48/200\n",
      "225/225 - 0s - loss: 0.3468 - accuracy: 0.8564 - val_loss: 0.3565 - val_accuracy: 0.8637 - 499ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "225/225 - 0s - loss: 0.3486 - accuracy: 0.8564 - val_loss: 0.3554 - val_accuracy: 0.8587 - 370ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "225/225 - 0s - loss: 0.3514 - accuracy: 0.8554 - val_loss: 0.3558 - val_accuracy: 0.8612 - 305ms/epoch - 1ms/step\n",
      "Epoch 51/200\n",
      "225/225 - 0s - loss: 0.3436 - accuracy: 0.8572 - val_loss: 0.3537 - val_accuracy: 0.8662 - 326ms/epoch - 1ms/step\n",
      "Epoch 52/200\n",
      "225/225 - 0s - loss: 0.3470 - accuracy: 0.8540 - val_loss: 0.3524 - val_accuracy: 0.8637 - 321ms/epoch - 1ms/step\n",
      "Epoch 53/200\n",
      "225/225 - 0s - loss: 0.3456 - accuracy: 0.8553 - val_loss: 0.3531 - val_accuracy: 0.8600 - 295ms/epoch - 1ms/step\n",
      "Epoch 54/200\n",
      "225/225 - 0s - loss: 0.3497 - accuracy: 0.8568 - val_loss: 0.3533 - val_accuracy: 0.8625 - 303ms/epoch - 1ms/step\n",
      "Epoch 55/200\n",
      "225/225 - 0s - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.3530 - val_accuracy: 0.8637 - 349ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "225/225 - 0s - loss: 0.3448 - accuracy: 0.8596 - val_loss: 0.3521 - val_accuracy: 0.8600 - 292ms/epoch - 1ms/step\n",
      "Epoch 57/200\n",
      "225/225 - 0s - loss: 0.3439 - accuracy: 0.8574 - val_loss: 0.3524 - val_accuracy: 0.8637 - 302ms/epoch - 1ms/step\n",
      "Epoch 58/200\n",
      "225/225 - 0s - loss: 0.3458 - accuracy: 0.8578 - val_loss: 0.3525 - val_accuracy: 0.8600 - 292ms/epoch - 1ms/step\n",
      "Epoch 59/200\n",
      "225/225 - 0s - loss: 0.3446 - accuracy: 0.8576 - val_loss: 0.3524 - val_accuracy: 0.8662 - 328ms/epoch - 1ms/step\n",
      "Epoch 60/200\n",
      "225/225 - 0s - loss: 0.3445 - accuracy: 0.8601 - val_loss: 0.3509 - val_accuracy: 0.8587 - 287ms/epoch - 1ms/step\n",
      "Epoch 61/200\n",
      "225/225 - 0s - loss: 0.3445 - accuracy: 0.8589 - val_loss: 0.3522 - val_accuracy: 0.8662 - 319ms/epoch - 1ms/step\n",
      "Epoch 62/200\n",
      "225/225 - 0s - loss: 0.3454 - accuracy: 0.8590 - val_loss: 0.3520 - val_accuracy: 0.8650 - 283ms/epoch - 1ms/step\n",
      "Epoch 63/200\n",
      "225/225 - 0s - loss: 0.3416 - accuracy: 0.8556 - val_loss: 0.3510 - val_accuracy: 0.8662 - 287ms/epoch - 1ms/step\n",
      "Epoch 64/200\n",
      "225/225 - 0s - loss: 0.3461 - accuracy: 0.8574 - val_loss: 0.3510 - val_accuracy: 0.8650 - 332ms/epoch - 1ms/step\n",
      "Epoch 65/200\n",
      "225/225 - 0s - loss: 0.3464 - accuracy: 0.8568 - val_loss: 0.3520 - val_accuracy: 0.8625 - 334ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "225/225 - 0s - loss: 0.3429 - accuracy: 0.8561 - val_loss: 0.3522 - val_accuracy: 0.8650 - 323ms/epoch - 1ms/step\n",
      "Epoch 67/200\n",
      "225/225 - 0s - loss: 0.3428 - accuracy: 0.8594 - val_loss: 0.3508 - val_accuracy: 0.8662 - 298ms/epoch - 1ms/step\n",
      "Epoch 68/200\n",
      "225/225 - 0s - loss: 0.3430 - accuracy: 0.8586 - val_loss: 0.3509 - val_accuracy: 0.8637 - 299ms/epoch - 1ms/step\n",
      "Epoch 69/200\n",
      "225/225 - 0s - loss: 0.3428 - accuracy: 0.8596 - val_loss: 0.3516 - val_accuracy: 0.8662 - 293ms/epoch - 1ms/step\n",
      "Epoch 70/200\n",
      "225/225 - 0s - loss: 0.3441 - accuracy: 0.8571 - val_loss: 0.3512 - val_accuracy: 0.8662 - 314ms/epoch - 1ms/step\n",
      "Epoch 71/200\n",
      "225/225 - 0s - loss: 0.3385 - accuracy: 0.8599 - val_loss: 0.3518 - val_accuracy: 0.8637 - 370ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "225/225 - 0s - loss: 0.3370 - accuracy: 0.8618 - val_loss: 0.3510 - val_accuracy: 0.8637 - 321ms/epoch - 1ms/step\n",
      "Epoch 73/200\n",
      "225/225 - 0s - loss: 0.3382 - accuracy: 0.8625 - val_loss: 0.3503 - val_accuracy: 0.8637 - 339ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "225/225 - 0s - loss: 0.3413 - accuracy: 0.8583 - val_loss: 0.3509 - val_accuracy: 0.8612 - 364ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "225/225 - 0s - loss: 0.3440 - accuracy: 0.8618 - val_loss: 0.3507 - val_accuracy: 0.8612 - 383ms/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "225/225 - 0s - loss: 0.3415 - accuracy: 0.8603 - val_loss: 0.3513 - val_accuracy: 0.8625 - 417ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "225/225 - 0s - loss: 0.3386 - accuracy: 0.8592 - val_loss: 0.3513 - val_accuracy: 0.8625 - 399ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "225/225 - 0s - loss: 0.3395 - accuracy: 0.8610 - val_loss: 0.3526 - val_accuracy: 0.8650 - 284ms/epoch - 1ms/step\n",
      "Epoch 79/200\n",
      "225/225 - 0s - loss: 0.3413 - accuracy: 0.8587 - val_loss: 0.3505 - val_accuracy: 0.8650 - 355ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "225/225 - 0s - loss: 0.3421 - accuracy: 0.8596 - val_loss: 0.3503 - val_accuracy: 0.8650 - 441ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "225/225 - 0s - loss: 0.3409 - accuracy: 0.8601 - val_loss: 0.3502 - val_accuracy: 0.8650 - 395ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "225/225 - 0s - loss: 0.3387 - accuracy: 0.8607 - val_loss: 0.3494 - val_accuracy: 0.8662 - 372ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "225/225 - 0s - loss: 0.3411 - accuracy: 0.8587 - val_loss: 0.3514 - val_accuracy: 0.8687 - 376ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "225/225 - 0s - loss: 0.3421 - accuracy: 0.8581 - val_loss: 0.3505 - val_accuracy: 0.8650 - 329ms/epoch - 1ms/step\n",
      "Epoch 85/200\n",
      "225/225 - 0s - loss: 0.3402 - accuracy: 0.8622 - val_loss: 0.3502 - val_accuracy: 0.8637 - 311ms/epoch - 1ms/step\n",
      "Epoch 86/200\n",
      "225/225 - 0s - loss: 0.3408 - accuracy: 0.8604 - val_loss: 0.3493 - val_accuracy: 0.8662 - 273ms/epoch - 1ms/step\n",
      "Epoch 87/200\n",
      "225/225 - 0s - loss: 0.3463 - accuracy: 0.8589 - val_loss: 0.3503 - val_accuracy: 0.8650 - 329ms/epoch - 1ms/step\n",
      "Epoch 88/200\n",
      "225/225 - 0s - loss: 0.3395 - accuracy: 0.8607 - val_loss: 0.3512 - val_accuracy: 0.8637 - 319ms/epoch - 1ms/step\n",
      "Epoch 89/200\n",
      "225/225 - 0s - loss: 0.3394 - accuracy: 0.8633 - val_loss: 0.3511 - val_accuracy: 0.8650 - 301ms/epoch - 1ms/step\n",
      "Epoch 90/200\n",
      "225/225 - 0s - loss: 0.3410 - accuracy: 0.8608 - val_loss: 0.3509 - val_accuracy: 0.8662 - 330ms/epoch - 1ms/step\n",
      "Epoch 91/200\n",
      "225/225 - 0s - loss: 0.3388 - accuracy: 0.8619 - val_loss: 0.3509 - val_accuracy: 0.8675 - 397ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "225/225 - 0s - loss: 0.3402 - accuracy: 0.8599 - val_loss: 0.3508 - val_accuracy: 0.8625 - 304ms/epoch - 1ms/step\n",
      "Epoch 93/200\n",
      "225/225 - 0s - loss: 0.3387 - accuracy: 0.8585 - val_loss: 0.3499 - val_accuracy: 0.8625 - 312ms/epoch - 1ms/step\n",
      "Epoch 94/200\n",
      "225/225 - 0s - loss: 0.3367 - accuracy: 0.8622 - val_loss: 0.3517 - val_accuracy: 0.8662 - 259ms/epoch - 1ms/step\n",
      "Epoch 95/200\n",
      "225/225 - 0s - loss: 0.3428 - accuracy: 0.8592 - val_loss: 0.3510 - val_accuracy: 0.8687 - 334ms/epoch - 1ms/step\n",
      "Epoch 96/200\n",
      "225/225 - 0s - loss: 0.3407 - accuracy: 0.8612 - val_loss: 0.3499 - val_accuracy: 0.8612 - 263ms/epoch - 1ms/step\n",
      "Epoch 97/200\n",
      "225/225 - 0s - loss: 0.3445 - accuracy: 0.8583 - val_loss: 0.3511 - val_accuracy: 0.8637 - 314ms/epoch - 1ms/step\n",
      "Epoch 98/200\n",
      "225/225 - 0s - loss: 0.3389 - accuracy: 0.8606 - val_loss: 0.3505 - val_accuracy: 0.8600 - 344ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "225/225 - 0s - loss: 0.3357 - accuracy: 0.8625 - val_loss: 0.3505 - val_accuracy: 0.8625 - 371ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "225/225 - 0s - loss: 0.3371 - accuracy: 0.8579 - val_loss: 0.3523 - val_accuracy: 0.8625 - 373ms/epoch - 2ms/step\n",
      "Epoch 101/200\n",
      "225/225 - 0s - loss: 0.3367 - accuracy: 0.8625 - val_loss: 0.3516 - val_accuracy: 0.8600 - 387ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "225/225 - 0s - loss: 0.3386 - accuracy: 0.8635 - val_loss: 0.3514 - val_accuracy: 0.8625 - 358ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "225/225 - 0s - loss: 0.3385 - accuracy: 0.8597 - val_loss: 0.3512 - val_accuracy: 0.8612 - 372ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "225/225 - 0s - loss: 0.3393 - accuracy: 0.8619 - val_loss: 0.3500 - val_accuracy: 0.8637 - 309ms/epoch - 1ms/step\n",
      "Epoch 105/200\n",
      "225/225 - 0s - loss: 0.3362 - accuracy: 0.8610 - val_loss: 0.3515 - val_accuracy: 0.8650 - 368ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "225/225 - 0s - loss: 0.3347 - accuracy: 0.8649 - val_loss: 0.3502 - val_accuracy: 0.8587 - 306ms/epoch - 1ms/step\n",
      "Epoch 107/200\n",
      "225/225 - 0s - loss: 0.3425 - accuracy: 0.8604 - val_loss: 0.3509 - val_accuracy: 0.8687 - 401ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "225/225 - 0s - loss: 0.3351 - accuracy: 0.8640 - val_loss: 0.3504 - val_accuracy: 0.8662 - 367ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "225/225 - 0s - loss: 0.3414 - accuracy: 0.8601 - val_loss: 0.3500 - val_accuracy: 0.8637 - 431ms/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "225/225 - 0s - loss: 0.3418 - accuracy: 0.8590 - val_loss: 0.3502 - val_accuracy: 0.8625 - 333ms/epoch - 1ms/step\n",
      "Epoch 111/200\n",
      "225/225 - 0s - loss: 0.3390 - accuracy: 0.8617 - val_loss: 0.3513 - val_accuracy: 0.8625 - 323ms/epoch - 1ms/step\n",
      "Epoch 112/200\n",
      "225/225 - 0s - loss: 0.3375 - accuracy: 0.8604 - val_loss: 0.3501 - val_accuracy: 0.8637 - 322ms/epoch - 1ms/step\n",
      "Epoch 113/200\n",
      "225/225 - 0s - loss: 0.3372 - accuracy: 0.8631 - val_loss: 0.3476 - val_accuracy: 0.8600 - 304ms/epoch - 1ms/step\n",
      "Epoch 114/200\n",
      "225/225 - 0s - loss: 0.3400 - accuracy: 0.8618 - val_loss: 0.3481 - val_accuracy: 0.8612 - 360ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "225/225 - 0s - loss: 0.3395 - accuracy: 0.8604 - val_loss: 0.3487 - val_accuracy: 0.8650 - 398ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "225/225 - 0s - loss: 0.3360 - accuracy: 0.8644 - val_loss: 0.3492 - val_accuracy: 0.8650 - 328ms/epoch - 1ms/step\n",
      "Epoch 117/200\n",
      "225/225 - 0s - loss: 0.3361 - accuracy: 0.8625 - val_loss: 0.3470 - val_accuracy: 0.8600 - 362ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "225/225 - 0s - loss: 0.3370 - accuracy: 0.8633 - val_loss: 0.3471 - val_accuracy: 0.8612 - 407ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "225/225 - 0s - loss: 0.3355 - accuracy: 0.8625 - val_loss: 0.3474 - val_accuracy: 0.8637 - 296ms/epoch - 1ms/step\n",
      "Epoch 120/200\n",
      "225/225 - 0s - loss: 0.3361 - accuracy: 0.8626 - val_loss: 0.3471 - val_accuracy: 0.8587 - 294ms/epoch - 1ms/step\n",
      "Epoch 121/200\n",
      "225/225 - 0s - loss: 0.3341 - accuracy: 0.8633 - val_loss: 0.3469 - val_accuracy: 0.8675 - 364ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "225/225 - 0s - loss: 0.3360 - accuracy: 0.8643 - val_loss: 0.3466 - val_accuracy: 0.8650 - 281ms/epoch - 1ms/step\n",
      "Epoch 123/200\n",
      "225/225 - 0s - loss: 0.3486 - accuracy: 0.8567 - val_loss: 0.3477 - val_accuracy: 0.8687 - 294ms/epoch - 1ms/step\n",
      "Epoch 124/200\n",
      "225/225 - 0s - loss: 0.3426 - accuracy: 0.8601 - val_loss: 0.3462 - val_accuracy: 0.8662 - 330ms/epoch - 1ms/step\n",
      "Epoch 125/200\n",
      "225/225 - 0s - loss: 0.3403 - accuracy: 0.8593 - val_loss: 0.3463 - val_accuracy: 0.8650 - 316ms/epoch - 1ms/step\n",
      "Epoch 126/200\n",
      "225/225 - 0s - loss: 0.3353 - accuracy: 0.8624 - val_loss: 0.3471 - val_accuracy: 0.8662 - 254ms/epoch - 1ms/step\n",
      "Epoch 127/200\n",
      "225/225 - 0s - loss: 0.3369 - accuracy: 0.8600 - val_loss: 0.3475 - val_accuracy: 0.8650 - 248ms/epoch - 1ms/step\n",
      "Epoch 128/200\n",
      "225/225 - 0s - loss: 0.3403 - accuracy: 0.8589 - val_loss: 0.3486 - val_accuracy: 0.8637 - 275ms/epoch - 1ms/step\n",
      "Epoch 129/200\n",
      "225/225 - 0s - loss: 0.3359 - accuracy: 0.8599 - val_loss: 0.3463 - val_accuracy: 0.8625 - 296ms/epoch - 1ms/step\n",
      "Epoch 130/200\n",
      "225/225 - 0s - loss: 0.3370 - accuracy: 0.8617 - val_loss: 0.3479 - val_accuracy: 0.8675 - 234ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "225/225 - 0s - loss: 0.3316 - accuracy: 0.8636 - val_loss: 0.3452 - val_accuracy: 0.8687 - 262ms/epoch - 1ms/step\n",
      "Epoch 132/200\n",
      "225/225 - 0s - loss: 0.3334 - accuracy: 0.8626 - val_loss: 0.3453 - val_accuracy: 0.8662 - 271ms/epoch - 1ms/step\n",
      "Epoch 133/200\n",
      "225/225 - 0s - loss: 0.3368 - accuracy: 0.8635 - val_loss: 0.3460 - val_accuracy: 0.8662 - 224ms/epoch - 997us/step\n",
      "Epoch 134/200\n",
      "225/225 - 0s - loss: 0.3372 - accuracy: 0.8633 - val_loss: 0.3455 - val_accuracy: 0.8650 - 239ms/epoch - 1ms/step\n",
      "Epoch 135/200\n",
      "225/225 - 1s - loss: 0.3382 - accuracy: 0.8592 - val_loss: 0.3459 - val_accuracy: 0.8687 - 598ms/epoch - 3ms/step\n",
      "Epoch 136/200\n",
      "225/225 - 0s - loss: 0.3355 - accuracy: 0.8636 - val_loss: 0.3452 - val_accuracy: 0.8675 - 241ms/epoch - 1ms/step\n",
      "Epoch 137/200\n",
      "225/225 - 0s - loss: 0.3349 - accuracy: 0.8600 - val_loss: 0.3452 - val_accuracy: 0.8650 - 479ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "225/225 - 0s - loss: 0.3347 - accuracy: 0.8642 - val_loss: 0.3445 - val_accuracy: 0.8650 - 442ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "225/225 - 0s - loss: 0.3315 - accuracy: 0.8651 - val_loss: 0.3449 - val_accuracy: 0.8637 - 286ms/epoch - 1ms/step\n",
      "Epoch 140/200\n",
      "225/225 - 0s - loss: 0.3354 - accuracy: 0.8642 - val_loss: 0.3451 - val_accuracy: 0.8625 - 267ms/epoch - 1ms/step\n",
      "Epoch 141/200\n",
      "225/225 - 0s - loss: 0.3370 - accuracy: 0.8621 - val_loss: 0.3438 - val_accuracy: 0.8625 - 421ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "225/225 - 0s - loss: 0.3357 - accuracy: 0.8632 - val_loss: 0.3451 - val_accuracy: 0.8650 - 296ms/epoch - 1ms/step\n",
      "Epoch 143/200\n",
      "225/225 - 0s - loss: 0.3359 - accuracy: 0.8615 - val_loss: 0.3454 - val_accuracy: 0.8625 - 253ms/epoch - 1ms/step\n",
      "Epoch 144/200\n",
      "225/225 - 0s - loss: 0.3391 - accuracy: 0.8593 - val_loss: 0.3446 - val_accuracy: 0.8675 - 257ms/epoch - 1ms/step\n",
      "Epoch 145/200\n",
      "225/225 - 0s - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3445 - val_accuracy: 0.8637 - 277ms/epoch - 1ms/step\n",
      "Epoch 146/200\n",
      "225/225 - 0s - loss: 0.3354 - accuracy: 0.8643 - val_loss: 0.3443 - val_accuracy: 0.8650 - 268ms/epoch - 1ms/step\n",
      "Epoch 147/200\n",
      "225/225 - 0s - loss: 0.3311 - accuracy: 0.8644 - val_loss: 0.3446 - val_accuracy: 0.8650 - 286ms/epoch - 1ms/step\n",
      "Epoch 148/200\n",
      "225/225 - 0s - loss: 0.3365 - accuracy: 0.8624 - val_loss: 0.3451 - val_accuracy: 0.8662 - 234ms/epoch - 1ms/step\n",
      "Epoch 149/200\n",
      "225/225 - 0s - loss: 0.3369 - accuracy: 0.8651 - val_loss: 0.3448 - val_accuracy: 0.8637 - 237ms/epoch - 1ms/step\n",
      "Epoch 150/200\n",
      "225/225 - 0s - loss: 0.3374 - accuracy: 0.8601 - val_loss: 0.3457 - val_accuracy: 0.8650 - 244ms/epoch - 1ms/step\n",
      "Epoch 151/200\n",
      "225/225 - 0s - loss: 0.3363 - accuracy: 0.8619 - val_loss: 0.3452 - val_accuracy: 0.8612 - 262ms/epoch - 1ms/step\n",
      "Epoch 152/200\n",
      "225/225 - 0s - loss: 0.3390 - accuracy: 0.8626 - val_loss: 0.3452 - val_accuracy: 0.8637 - 284ms/epoch - 1ms/step\n",
      "Epoch 153/200\n",
      "225/225 - 0s - loss: 0.3327 - accuracy: 0.8656 - val_loss: 0.3447 - val_accuracy: 0.8612 - 241ms/epoch - 1ms/step\n",
      "Epoch 154/200\n",
      "225/225 - 0s - loss: 0.3330 - accuracy: 0.8653 - val_loss: 0.3453 - val_accuracy: 0.8675 - 256ms/epoch - 1ms/step\n",
      "Epoch 155/200\n",
      "225/225 - 0s - loss: 0.3420 - accuracy: 0.8600 - val_loss: 0.3448 - val_accuracy: 0.8625 - 249ms/epoch - 1ms/step\n",
      "Epoch 156/200\n",
      "225/225 - 0s - loss: 0.3362 - accuracy: 0.8621 - val_loss: 0.3448 - val_accuracy: 0.8600 - 307ms/epoch - 1ms/step\n",
      "Epoch 157/200\n",
      "225/225 - 0s - loss: 0.3373 - accuracy: 0.8615 - val_loss: 0.3446 - val_accuracy: 0.8687 - 264ms/epoch - 1ms/step\n",
      "Epoch 158/200\n",
      "225/225 - 0s - loss: 0.3355 - accuracy: 0.8611 - val_loss: 0.3440 - val_accuracy: 0.8650 - 288ms/epoch - 1ms/step\n",
      "Epoch 159/200\n",
      "225/225 - 0s - loss: 0.3378 - accuracy: 0.8615 - val_loss: 0.3458 - val_accuracy: 0.8662 - 229ms/epoch - 1ms/step\n",
      "Epoch 160/200\n",
      "225/225 - 0s - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3460 - val_accuracy: 0.8637 - 244ms/epoch - 1ms/step\n",
      "Epoch 161/200\n",
      "225/225 - 0s - loss: 0.3359 - accuracy: 0.8642 - val_loss: 0.3437 - val_accuracy: 0.8675 - 236ms/epoch - 1ms/step\n",
      "Epoch 162/200\n",
      "225/225 - 0s - loss: 0.3424 - accuracy: 0.8611 - val_loss: 0.3434 - val_accuracy: 0.8675 - 237ms/epoch - 1ms/step\n",
      "Epoch 163/200\n",
      "225/225 - 0s - loss: 0.3359 - accuracy: 0.8662 - val_loss: 0.3441 - val_accuracy: 0.8650 - 240ms/epoch - 1ms/step\n",
      "Epoch 164/200\n",
      "225/225 - 0s - loss: 0.3420 - accuracy: 0.8622 - val_loss: 0.3436 - val_accuracy: 0.8675 - 254ms/epoch - 1ms/step\n",
      "Epoch 165/200\n",
      "225/225 - 0s - loss: 0.3322 - accuracy: 0.8646 - val_loss: 0.3445 - val_accuracy: 0.8675 - 253ms/epoch - 1ms/step\n",
      "Epoch 166/200\n",
      "225/225 - 0s - loss: 0.3380 - accuracy: 0.8626 - val_loss: 0.3448 - val_accuracy: 0.8662 - 237ms/epoch - 1ms/step\n",
      "Epoch 167/200\n",
      "225/225 - 0s - loss: 0.3354 - accuracy: 0.8649 - val_loss: 0.3456 - val_accuracy: 0.8662 - 248ms/epoch - 1ms/step\n",
      "Epoch 168/200\n",
      "225/225 - 0s - loss: 0.3361 - accuracy: 0.8610 - val_loss: 0.3457 - val_accuracy: 0.8637 - 257ms/epoch - 1ms/step\n",
      "Epoch 169/200\n",
      "225/225 - 0s - loss: 0.3390 - accuracy: 0.8604 - val_loss: 0.3448 - val_accuracy: 0.8650 - 254ms/epoch - 1ms/step\n",
      "Epoch 170/200\n",
      "225/225 - 0s - loss: 0.3325 - accuracy: 0.8618 - val_loss: 0.3436 - val_accuracy: 0.8637 - 311ms/epoch - 1ms/step\n",
      "Epoch 171/200\n",
      "225/225 - 0s - loss: 0.3394 - accuracy: 0.8610 - val_loss: 0.3440 - val_accuracy: 0.8662 - 234ms/epoch - 1ms/step\n",
      "Epoch 172/200\n",
      "225/225 - 0s - loss: 0.3324 - accuracy: 0.8624 - val_loss: 0.3442 - val_accuracy: 0.8662 - 274ms/epoch - 1ms/step\n",
      "Epoch 173/200\n",
      "225/225 - 0s - loss: 0.3334 - accuracy: 0.8654 - val_loss: 0.3442 - val_accuracy: 0.8687 - 244ms/epoch - 1ms/step\n",
      "Epoch 174/200\n",
      "225/225 - 0s - loss: 0.3361 - accuracy: 0.8624 - val_loss: 0.3433 - val_accuracy: 0.8700 - 236ms/epoch - 1ms/step\n",
      "Epoch 175/200\n",
      "225/225 - 0s - loss: 0.3405 - accuracy: 0.8618 - val_loss: 0.3443 - val_accuracy: 0.8675 - 267ms/epoch - 1ms/step\n",
      "Epoch 176/200\n",
      "225/225 - 0s - loss: 0.3350 - accuracy: 0.8647 - val_loss: 0.3437 - val_accuracy: 0.8650 - 317ms/epoch - 1ms/step\n",
      "Epoch 177/200\n",
      "225/225 - 0s - loss: 0.3354 - accuracy: 0.8636 - val_loss: 0.3443 - val_accuracy: 0.8637 - 343ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "225/225 - 0s - loss: 0.3388 - accuracy: 0.8624 - val_loss: 0.3443 - val_accuracy: 0.8662 - 280ms/epoch - 1ms/step\n",
      "Epoch 179/200\n",
      "225/225 - 0s - loss: 0.3380 - accuracy: 0.8607 - val_loss: 0.3438 - val_accuracy: 0.8675 - 256ms/epoch - 1ms/step\n",
      "Epoch 180/200\n",
      "225/225 - 0s - loss: 0.3341 - accuracy: 0.8642 - val_loss: 0.3434 - val_accuracy: 0.8625 - 248ms/epoch - 1ms/step\n",
      "Epoch 181/200\n",
      "225/225 - 0s - loss: 0.3375 - accuracy: 0.8606 - val_loss: 0.3438 - val_accuracy: 0.8625 - 259ms/epoch - 1ms/step\n",
      "Epoch 182/200\n",
      "225/225 - 0s - loss: 0.3282 - accuracy: 0.8661 - val_loss: 0.3441 - val_accuracy: 0.8612 - 235ms/epoch - 1ms/step\n",
      "Epoch 183/200\n",
      "225/225 - 0s - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3452 - val_accuracy: 0.8650 - 243ms/epoch - 1ms/step\n",
      "Epoch 184/200\n",
      "225/225 - 0s - loss: 0.3339 - accuracy: 0.8639 - val_loss: 0.3459 - val_accuracy: 0.8675 - 244ms/epoch - 1ms/step\n",
      "Epoch 185/200\n",
      "225/225 - 0s - loss: 0.3390 - accuracy: 0.8619 - val_loss: 0.3451 - val_accuracy: 0.8650 - 235ms/epoch - 1ms/step\n",
      "Epoch 186/200\n",
      "225/225 - 0s - loss: 0.3372 - accuracy: 0.8610 - val_loss: 0.3451 - val_accuracy: 0.8600 - 251ms/epoch - 1ms/step\n",
      "Epoch 187/200\n",
      "225/225 - 0s - loss: 0.3386 - accuracy: 0.8607 - val_loss: 0.3453 - val_accuracy: 0.8650 - 260ms/epoch - 1ms/step\n",
      "Epoch 188/200\n",
      "225/225 - 0s - loss: 0.3349 - accuracy: 0.8637 - val_loss: 0.3451 - val_accuracy: 0.8625 - 253ms/epoch - 1ms/step\n",
      "Epoch 189/200\n",
      "225/225 - 0s - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3449 - val_accuracy: 0.8650 - 244ms/epoch - 1ms/step\n",
      "Epoch 190/200\n",
      "225/225 - 0s - loss: 0.3415 - accuracy: 0.8601 - val_loss: 0.3442 - val_accuracy: 0.8637 - 253ms/epoch - 1ms/step\n",
      "Epoch 191/200\n",
      "225/225 - 0s - loss: 0.3351 - accuracy: 0.8615 - val_loss: 0.3443 - val_accuracy: 0.8637 - 261ms/epoch - 1ms/step\n",
      "Epoch 192/200\n",
      "225/225 - 0s - loss: 0.3347 - accuracy: 0.8635 - val_loss: 0.3453 - val_accuracy: 0.8675 - 256ms/epoch - 1ms/step\n",
      "Epoch 193/200\n",
      "225/225 - 0s - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.3452 - val_accuracy: 0.8662 - 449ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "225/225 - 0s - loss: 0.3372 - accuracy: 0.8624 - val_loss: 0.3442 - val_accuracy: 0.8675 - 258ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "225/225 - 0s - loss: 0.3373 - accuracy: 0.8628 - val_loss: 0.3442 - val_accuracy: 0.8625 - 243ms/epoch - 1ms/step\n",
      "Epoch 196/200\n",
      "225/225 - 0s - loss: 0.3358 - accuracy: 0.8635 - val_loss: 0.3450 - val_accuracy: 0.8662 - 238ms/epoch - 1ms/step\n",
      "Epoch 197/200\n",
      "225/225 - 0s - loss: 0.3410 - accuracy: 0.8594 - val_loss: 0.3459 - val_accuracy: 0.8637 - 234ms/epoch - 1ms/step\n",
      "Epoch 198/200\n",
      "225/225 - 0s - loss: 0.3353 - accuracy: 0.8626 - val_loss: 0.3451 - val_accuracy: 0.8625 - 223ms/epoch - 993us/step\n",
      "Epoch 199/200\n",
      "225/225 - 0s - loss: 0.3395 - accuracy: 0.8614 - val_loss: 0.3454 - val_accuracy: 0.8625 - 237ms/epoch - 1ms/step\n",
      "Epoch 200/200\n",
      "225/225 - 0s - loss: 0.3373 - accuracy: 0.8615 - val_loss: 0.3443 - val_accuracy: 0.8662 - 223ms/epoch - 993us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6115ddbe0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 32, epochs = 200, validation_split = 0.1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 693us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1598    0]\n",
      " [ 402    0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.9 % of data was classified correctly\n",
      "79.9 accuracy is following\n"
     ]
    }
   ],
   "source": [
    "print(((cm[0][0] + cm[1][1])* 100) / len(y_test), '% of data was classified correctly')\n",
    "print((cm[0][0]+cm[1][1])*100/len(y_test),\"accuracy is following\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "f82e9eef39fec3b4432bd3d531b07136b7f172564442eec42315ae171445fe6f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
